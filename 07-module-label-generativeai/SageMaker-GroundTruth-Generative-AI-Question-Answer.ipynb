{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "337df1d5",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Amazon SageMaker Ground Truth Demonstration for Generating Question and Answer pairs\n",
    "\n",
    "\n",
    "1. [Introduction](#Introduction)\n",
    "2. [Prerequisites](#Prerequisites)\n",
    "    1. [Create a Work Team](#Create-Workteam)\n",
    "    2. [IAM Role Set up](#IAM-role-set-up)\n",
    "    3. [Prepare the data](#Prepare-the-data)\n",
    "3. [Run a Ground Truth labeling job](#Run-a-Ground-Truth-labeling-job)\n",
    "    1. [Specify Parameters for Labeling Job](#Specify-Labeling-Parameters)\n",
    "    2. [Create the instruction template](#Create-the-instruction-template)\n",
    "    3. [Create a Labeling Job](#Create-a-Labeling-Job)\n",
    "    4. [Gather Human feedback through labeling portal](#Gather-human-feedback-through-labeling-portal)\n",
    "    5. [Monitoring Labeling Job Status](#Monitoring-Labeling-Job-Status)\n",
    "4. [Post Processing and Analysis of SageMaker GroundTruth Labeling Job Results](#Post-Processing-and-Analysis-of-SageMaker-Ground-Truth-Labeling-Job-Results)\n",
    "    1. [Merging Worker Responses](#Merging-Worker-Responses-into-a-Consolidated-JSON-File)\n",
    "    2. [Analyzing Time Spent on Labeling Tasks](#Analyzing-Time-Spent-on-Labeling-Tasks)\n",
    "    3. [Consolidating Worker Responses and Output Manifest](#Consolidating-Worker-Responses-and-Output-Manifest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4594bc8f",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This notebook guides you through the process of setting up a Human-in-the-Loop (HITL) workflow for Reinforcement Learning from Human Feedback (RLHF) using Amazon SageMaker Ground Truth's Question and Answer template. This labeling UI is designed to facilitate human annotators in reading a text passage and generating questions and answers to build a Q&A demonstration dataset. This UI supports customizable text input and flexible question-answer generation, with options to create questions referencing entire passages or highlight specific text portions for targeted Q&A. The color-coded matching feature visually links questions to relevant text sections, enhancing the annotation process. \n",
    "\n",
    "The primary objectives of this interface are to produce diverse, context-rich Q&A datasets that capture the nuances of human text comprehension, ultimately supporting the development of more sophisticated NLP models.\n",
    "\n",
    "Some Common Use cases:\n",
    "\n",
    "1. Improving chatbot and virtual assistant capabilities, ensuring they can understand and respond to customer queries accurately.\n",
    "2. Enhancing search engine question-answering features\n",
    "3. Creating educational content where models can assist in generating questions and answers for students based on reading materials.\n",
    "4. Assisting content creators in generating relevant questions and answers for articles, blogs, and other textual content.\n",
    "5. Supporting research in natural language understanding and generation\n",
    "\n",
    "The steps include  setting up necessary Ground Truth pre-requisites, downloading an input manifest JSON, creating a worker task template, creating and monitoring a labeling job, and post-processing the results to deliver a consolidated dataset with worker responses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1c51be",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "You will create some of the resources you need to launch a Ground Truth labeling job in this notebook.\n",
    "\n",
    "Lets get the latest version of SDK, restart kernel and import some essential libraries to set up the environment for downloading data, handling JSON files, and leveraging AWS services for machine learning workflows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a0594b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q --upgrade pip\n",
    "!pip install awscli -q --upgrade\n",
    "!pip install botocore -q --upgrade\n",
    "!pip install sagemaker -q --upgrade\n",
    "!pip install py7zr\n",
    "!pip install datasets\n",
    "\n",
    "# NOTE: Restart Kernel after the above command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f8d7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import datetime\n",
    "import json\n",
    "import sagemaker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd256839",
   "metadata": {},
   "source": [
    "### Create-Workteam \n",
    "A work team is a group of workers that complete labeling tasks. If you want to preview the worker UI and execute the labeling task you will need to create a private work team, add yourself as a worker to this team, and provide the work team ARN below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04f7611",
   "metadata": {},
   "outputs": [],
   "source": [
    "WORKTEAM_ARN = \"\"\n",
    "\n",
    "print(f\"This notebook will use the work team ARN: {WORKTEAM_ARN}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a0d3f1",
   "metadata": {},
   "source": [
    "### IAM-role-set-up\n",
    "The IAM execution role you used to create this notebook instance must have the following permissions:\n",
    "\n",
    "AWS managed policy AmazonSageMakerGroundTruthExecution. Run the following code-block to see your IAM execution role name. This GIF demonstrates how to add this policy to an IAM role in the IAM console. You can also find instructions in the IAM User Guide: Adding and removing IAM identity permissions.\n",
    "\n",
    "When you create your role, you specify Amazon S3 permissions. Make sure that your IAM role has access to the S3 bucket that you plan to use in this example. If you do not specify an S3 bucket in this notebook, the default bucket in the AWS region you are running this notebook instance will be used. If you do not require granular permissions, you can attach AmazonS3FullAccess to your role."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73f527a",
   "metadata": {},
   "outputs": [],
   "source": [
    "role = sagemaker.get_execution_role()\n",
    "role_name = role.split(\"/\")[-1]\n",
    "print(\"********************************************************************************\")\n",
    "print(\"The IAM execution role name:\", role_name)\n",
    "print(\"The IAM execution role ARN:\", role)\n",
    "print(\"********************************************************************************\")\n",
    "print(\n",
    "    \"IMPORTANT: Make sure this execution role has the AWS Managed policy AmazonGroundTruthExecution attached.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2878113",
   "metadata": {},
   "source": [
    "### Prepare-the-data\n",
    "Before we create the labeling job, we need to ensure that the input data is in the format expected by GroundTruth.\n",
    "<b>gt_input_manifest_qna.json</b> contains sample text passages in Ground Truth Input format under the \"source\" field. We upload the file to Amazon S3 bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2196fc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize SageMaker session and S3 resource\n",
    "sess = sagemaker.Session()\n",
    "bucket = sess.default_bucket()\n",
    "s3 = boto3.resource('s3')\n",
    "s3_client = boto3.client('s3')\n",
    "region = boto3.session.Session().region_name\n",
    "\n",
    "# Define the S3 bucket and folder\n",
    "bucket_name = bucket\n",
    "prefix = 'genai'\n",
    "output_file = 'data/gt_input_manifest_qna.json'\n",
    "s3_path = f\"{prefix}/{output_file}\"\n",
    "\n",
    "# Upload the file to S3\n",
    "s3.Bucket(bucket_name).upload_file(output_file, s3_path)\n",
    "input_manifest_uri = f\"s3://{bucket_name}/{s3_path}\"\n",
    "\n",
    "print(f\"File uploaded to s3://{bucket_name}/{s3_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9514d8fa",
   "metadata": {},
   "source": [
    "## Run-a-Ground-Truth-labeling-job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2eb876",
   "metadata": {},
   "source": [
    "###  Create-the-instruction-template\n",
    "\n",
    "The instruction template is designed to facilitate the creation of high-quality question-answer datasets for natural language processing and machine learning applications. It contains instructions to help them perform their task accurately. Annotators can engage deeply with text passages, generating thoughtful questions and answers that reflect human-like comprehension and reasoning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2325c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "def make_template(save_fname=\"instructions_qna.liquid\"):\n",
    "    template = \"\"\"\n",
    "<html>\n",
    "  <head>\n",
    "    <link rel=\"stylesheet\" href=\"https://assets.crowd.aws/css/crowd-html-elements-v2.css\" />\n",
    "    <title>Question-Answer Generation Tool</title>\n",
    "    <script src=\"https://assets.crowd.aws/crowd-html-elements-v2.js\"></script>\n",
    "  </head>\n",
    "  <body>\n",
    "    <div>\n",
    "      <crowd-form id=\"crowd-form-qa\" style=\"display: none\"></crowd-form>\n",
    "      <crowd-question-answer-generation\n",
    "        crowd-form-element-id=\"crowd-form-qa\"\n",
    "        text='{{ task.input.source }}'\n",
    "        min-questions=\"1\"\n",
    "        max-questions=\"5\"\n",
    "        question-min-words=\"1\"\n",
    "        question-max-words=\"20\"\n",
    "        answer-min-words=\"1\"\n",
    "        answer-max-words=\"20\"\n",
    "        question-tags='[\"What\", \"Why\", \"When\", \"Where\", \"Which\", \"Who\", \"How\"]'\n",
    "        allow-custom-question-tags=\"true\"\n",
    "        instructions='- Create questions and answers based on the provided text passage.\n",
    "                      - Select at least 1 text reference for a Q&A pair (unless it references the entire text passage)\n",
    "                      - Question tags are \"Who\", \"What\", \"When\", \"Where\", \"Why\", \"How\", \"Which\" and \"Whose\". Select the appropriate tag based on your question.\n",
    "                      - Other types of questions are permitted (example- yes/no, completion statements etc). If applicable, add a custom tag for such Q&A pairs.'></crowd-question-answer-generation>\n",
    "    </div>\n",
    "    <script src=\"https://assets.crowd.aws/crowd-html-elements.js\"></script>\n",
    "  </body>\n",
    "</html>\n",
    "    \"\"\"\n",
    "    with open(save_fname, \"w\") as f:\n",
    "        f.write(template)\n",
    "\n",
    "# Create the template file locally\n",
    "make_template(save_fname=\"./instructions_qna.liquid\")\n",
    "\n",
    "# Define the S3 path\n",
    "file_name = 'instructions_qna.liquid'\n",
    "ui_s3_path = f\"{prefix}/{file_name}\"\n",
    "UITEMPLATES3URI = f\"s3://{bucket}/{ui_s3_path}\"\n",
    "\n",
    "# Upload the file to S3 using the s3 client\n",
    "s3_client.upload_file(\"./instructions_qna.liquid\", bucket, ui_s3_path)\n",
    "\n",
    "print(f\"File uploaded to {UITEMPLATES3URI}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d742c776",
   "metadata": {},
   "source": [
    "### Specify-Labeling-Parameters\n",
    "Specify a Labeling Job Name, Parameters for the Labeling such as TaskTitle, TaskDescription, TaskKeywords and use the CreateLabelingJob API to launch the Ground truth Labeling Job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1b8130",
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.datetime.now()\n",
    "timestamp_str = now.strftime(\"%Y%m%d-%H%M%S\")\n",
    "labeling_job_name = \"immersionday-genai-qna-\" + timestamp_str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37572f5",
   "metadata": {},
   "source": [
    "### Create-a-Labeling-Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8cb91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = boto3.client('sagemaker')\n",
    "\n",
    "client.create_labeling_job(\n",
    "    LabelingJobName=labeling_job_name,\n",
    "    LabelAttributeName='label',\n",
    "    InputConfig={\n",
    "        'DataSource': {\n",
    "            'S3DataSource': {\n",
    "                'ManifestS3Uri': input_manifest_uri  #Enter S3 URI of Input Data Json\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    OutputConfig={\n",
    "        'S3OutputPath': f's3://{bucket}/output/' #Enter S3 URI of Output folder\n",
    "    },\n",
    "    RoleArn=role, #Enter IAM Sagemaker Execution Role here,\n",
    "    HumanTaskConfig={\n",
    "        'WorkteamArn': WORKTEAM_ARN, #Enter Workteam ARN\n",
    "        'UiConfig': {\n",
    "            'UiTemplateS3Uri': UITEMPLATES3URI #Enter S3 URI of UI template\n",
    "        },\n",
    "        'TaskKeywords': [\n",
    "            'QnA',\n",
    "        ],\n",
    "        'TaskTitle': 'Generative AI - Question and Answer pairs',\n",
    "        'TaskDescription': \"Create questions and answers based on the provided text passage.\",\n",
    "        'NumberOfHumanWorkersPerDataObject': 1,\n",
    "        'TaskTimeLimitInSeconds': 60*30,\n",
    "        'TaskAvailabilityLifetimeInSeconds': 60*60*24*10,\n",
    "        'MaxConcurrentTaskCount': 100\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48480676",
   "metadata": {},
   "source": [
    "### Gather-human-feedback-through-labeling-portal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4de8abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "workforce = client.describe_workforce(WorkforceName=\"default\")\n",
    "worker_portal_url = 'https://' + workforce[\"Workforce\"][\"SubDomain\"]\n",
    "\n",
    "\n",
    "# Display the URL and instructions\n",
    "display(HTML(f\"\"\"\n",
    "<body>\n",
    "<h4>Gather human preference data</h4>\n",
    "<p>Please complete the human evaluation tasks available in the labeling portal.</p>\n",
    "<p><a href=\"{worker_portal_url}\">{worker_portal_url}</a>\n",
    "<p><b>Ensure all tasks are completed before proceeding to the next steps in this notebook.<b></p>\n",
    "<body>\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d18941",
   "metadata": {},
   "source": [
    "### Monitoring-Labeling-Job-Status\n",
    "We track the status of the ongoing labeling job. It is essential to monitor the job's progress and wait for its completion by the annotators. Once the labeling job is finished, we can then proceed to gather feedback from the annotators. This process ensures that we only collect feedback after the entire job is completed, thereby maintaining the accuracy and reliability of the feedback collected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183e37f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "client.describe_labeling_job(LabelingJobName=labeling_job_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ea1df2",
   "metadata": {},
   "source": [
    "## Post-Processing-and-Analysis-of-SageMaker-Ground-Truth-Labeling-Job-Results\n",
    "<b>[OPTIONAL]</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c6abfb",
   "metadata": {},
   "source": [
    "### Merging-Worker-Responses-into-a-Consolidated-JSON-File\n",
    "\n",
    "This section focuses on combining all individual worker responses into a single, comprehensive JSON file. We gather the individual JSON files from the \"worker-response\" folder, each representing a worker's answers to labeling tasks, and merge them into one consolidated file. The resulting consolidated file makes it easier to analyze worker performance, compare responses across different tasks, and prepare the data for further processing or quality checks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0547d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "\n",
    "s3_client = boto3.client('s3')\n",
    "\n",
    "def merge_json_files(bucket, prefix, output_bucket, output_key):\n",
    "    merged_data = []\n",
    "\n",
    "    # List iteration buckets\n",
    "    iteration_response = s3_client.list_objects_v2(Bucket=bucket, Prefix=prefix, Delimiter='/')\n",
    "    for iteration in iteration_response.get('CommonPrefixes', []):\n",
    "        # List JSON objects in each iteration bucket\n",
    "        json_response = s3_client.list_objects_v2(Bucket=bucket, Prefix=iteration['Prefix'])\n",
    "        for obj in json_response.get('Contents', []):\n",
    "            # Read and append each JSON file, adding the S3 URI or file name\n",
    "            key = obj['Key']\n",
    "            json_obj = s3_client.get_object(Bucket=bucket, Key=key)\n",
    "            json_data = json.loads(json_obj['Body'].read().decode('utf-8'))\n",
    "            json_data['workerjsonUri'] = f\"s3://{bucket}/{key}\"  # Add the source S3 URI to the JSON object\n",
    "            merged_data.append(json_data)  # Append the modified JSON object\n",
    "\n",
    "    # Write merged data to a new JSON file in S3\n",
    "    merged_json = json.dumps(merged_data)\n",
    "    s3_client.put_object(Body=merged_json, Bucket=output_bucket, Key=output_key)\n",
    "    print(f\"Merged JSON file created at https://s3.console.aws.amazon.com/s3/object/{output_bucket}?region={region}&prefix={output_key}\")\n",
    "\n",
    "# Replace with your actual bucket names and prefixes\n",
    "source_bucket_name = bucket\n",
    "iteration_prefix = f'output/{labeling_job_name}/annotations/worker-response/iteration-1/'\n",
    "output_bucket_name = bucket\n",
    "output_key = f'output/{labeling_job_name}/merged-worker-data.json'\n",
    "\n",
    "merge_json_files(source_bucket_name, iteration_prefix, output_bucket_name, output_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a187c7f",
   "metadata": {},
   "source": [
    "### Analyzing-Time-Spent-on-Labeling-Tasks\n",
    "This section analyzes the time spent on labeling tasks in our SageMaker Ground Truth job, from the consolidated worker json file. It calculates the total time invested across all tasks, counts the number of completed tasks, and determines the average time per task. These insights help us understand the overall effort of our labeling project, assess its scale, and plan future workflows more effectively. By examining these time metrics, we can make informed decisions about resource allocation and set realistic expectations for upcoming labeling jobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1e8459",
   "metadata": {},
   "outputs": [],
   "source": [
    "from colorama import Fore, Back, Style, init\n",
    "\n",
    "init(autoreset=True)  # Initialize colorama\n",
    "\n",
    "def calculate_and_display_average_time(bucket, key):\n",
    "    json_obj = s3_client.get_object(Bucket=bucket, Key=key)\n",
    "    merged_json_data = json.loads(json_obj['Body'].read().decode('utf-8'))\n",
    "    total_time = 0\n",
    "    count = 0\n",
    "    for json_data in merged_json_data:\n",
    "        if 'answers' in json_data:\n",
    "            for answer in json_data['answers']:\n",
    "                if 'timeSpentInSeconds' in answer:\n",
    "                    total_time += answer['timeSpentInSeconds']\n",
    "                    count += 1\n",
    "    \n",
    "    average_time = total_time / count if count > 0 else 0\n",
    "    \n",
    "    # Create a fancy display\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(Fore.CYAN + Style.BRIGHT + \"     LABELING TASK SUMMARY     \")\n",
    "    print(\"=\"*50 + \"\\n\")\n",
    "    \n",
    "    print(Fore.YELLOW + \"üìä \" + Style.BRIGHT + \"Count of Tasks:\")\n",
    "    print(Fore.WHITE + f\"   {count:,} tasks\")\n",
    "    \n",
    "    print(Fore.YELLOW + \"\\n‚è±Ô∏è \" + Style.BRIGHT + \"Total Time Spent:\")\n",
    "    print(Fore.WHITE + f\"   {total_time:.2f} seconds\")\n",
    "    print(Fore.WHITE + f\"   ({total_time / 3600:.2f} hours)\")\n",
    "    \n",
    "    print(Fore.YELLOW + \"\\n‚åõ \" + Style.BRIGHT + \"Average Time per Task:\")\n",
    "    print(Fore.WHITE + f\"   {average_time:.2f} seconds\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "\n",
    "calculate_and_display_average_time(output_bucket_name, output_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c55aa5",
   "metadata": {},
   "source": [
    "### Consolidating-Worker-Responses-and-Output-Manifest\n",
    "\n",
    "This section consolidates our labeling project data into a comprehensive single file. We merge information from two key sources: the worker responses and the output manifest. By combining the \"source\" data from the output manifest with the \"answers\" provided by workers, we create a unified view of all labeling tasks. This consolidation streamlines our data analysis process, allowing us to easily connect each task's original source with its corresponding worker annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9528e97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_data_with_manifest(output_manifest_bucket, output_manifest_key, merged_data_bucket, merged_data_key):\n",
    "    try:\n",
    "        # Fetch and load the output manifest file\n",
    "        manifest_obj = s3_client.get_object(Bucket=output_manifest_bucket, Key=output_manifest_key)\n",
    "        manifest_data = manifest_obj['Body'].read().decode('utf-8').splitlines()\n",
    "        \n",
    "        # Load the merged JSON data\n",
    "        merged_data_obj = s3_client.get_object(Bucket=merged_data_bucket, Key=merged_data_key)\n",
    "        merged_data = json.loads(merged_data_obj['Body'].read().decode('utf-8'))\n",
    "        \n",
    "        # Convert merged data to a dictionary for easier lookup based on workerjsonUri\n",
    "        merged_data_dict = {item['workerjsonUri']: item for item in merged_data}\n",
    "        \n",
    "        final_data = []\n",
    "        \n",
    "        for line in manifest_data:\n",
    "            manifest_entry = json.loads(line)\n",
    "            worker_response_ref = manifest_entry.get(\"label-metadata\", {}).get(\"worker-response-ref\")\n",
    "            \n",
    "            # Find the matching entry in the merged data\n",
    "            if worker_response_ref in merged_data_dict:\n",
    "                # Merge the manifest data with the corresponding worker response data\n",
    "                combined_data = {**manifest_entry, **merged_data_dict[worker_response_ref]}\n",
    "                final_data.append(combined_data)\n",
    "        \n",
    "        # Optionally, write the final merged data to a new file in S3 or handle it as needed\n",
    "        final_json = json.dumps(final_data)\n",
    "        final_output_key = f'output/{labeling_job_name}/final-merged-data.json'  # Customize this as needed\n",
    "        s3_client.put_object(Body=final_json, Bucket=output_manifest_bucket, Key=final_output_key)\n",
    "        print(f\"Final merged JSON file created at https://s3.console.aws.amazon.com/s3/object/{output_manifest_bucket}?region={region}&prefix={final_output_key}\")\n",
    "    \n",
    "    except s3_client.exceptions.NoSuchKey as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "# Replace with your actual bucket names and keys\n",
    "output_manifest_bucket = bucket\n",
    "output_manifest_key = f'output/{labeling_job_name}/manifests/output/output.manifest'\n",
    "merged_data_bucket = bucket\n",
    "merged_data_key = f'output/{labeling_job_name}/merged-worker-data.json'\n",
    "\n",
    "merge_data_with_manifest(output_manifest_bucket, output_manifest_key, merged_data_bucket, merged_data_key)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
