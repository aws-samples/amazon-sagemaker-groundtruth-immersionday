{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bring your own model to create a Active Learning Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Using this Notebook\n",
    "\n",
    "Please set the image to *TensorFlow 2.10.0  Python 3.9 CPU Optimized* and kernel to  *Python 3*  when running this notebook .Select instance type as `ml.t3.medium`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "This notebook is comprised of two parts , In Part 1, we show you how you can containerize your own Machine Learning model and push it to [Amazon Elastic Container Registry (ECR)](https://docs.aws.amazon.com/AmazonECR/latest/userguide/what-is-ecr.html). This notebook will produce an Image ID that you can use to integrate your model into an active learning workflow. In this part, we will leverage sagemaker studio image build  which is a convenience package that allows data scientists and developers to easily build custom container images from your Studio notebooks via a new [CLI](https://github.com/aws-samples/sagemaker-studio-image-build-cli) . The new CLI eliminates the need to manually set up and connect to Docker build environments for building container images in Amazon SageMaker Studio. \n",
    "\n",
    "We will also leverage leverage [AWS SAM](https://aws.amazon.com/serverless/sam/)  to manage and deploy AWS Cloudformation templates that will be used  for Active Labeling workflow. \n",
    "\n",
    "In the Part 2, we will use this model to create an automated labeling workflow for a text-classification labeling job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Part 1:  Build you own ML model and push to ECR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install sagemaker studio image build  and AWS SAM to manage and deploy AWS Cloudformation template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install --upgrade setuptools  sagemaker-studio-image-build aws-sam-cli"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restart your kernel for this notebook to use updated packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%html\n",
    "\n",
    "<p><b>Restart your kernel for this notebook to use update package.</b></p>\n",
    "<button class=\"sm-command-button\" data-commandlinker-command=\"kernelmenu:restart\" style=\"display:none;\">Restart Kernel</button>\n",
    "\n",
    "<script>\n",
    "try {\n",
    "    els = document.getElementsByClassName(\"sm-command-button\");\n",
    "    els[0].click();\n",
    "}\n",
    "catch(err) {\n",
    "    // NoOp\n",
    "}    \n",
    "</script>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify sagemaker-studio-image-build and aws-sam-cli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "sam  --version\n",
    "sm-docker --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Setup SageMaker environment and variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os, sys, sagemaker, tensorflow as tf, pandas as pd, boto3, numpy as np\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.tensorflow import TensorFlow\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "role = get_execution_role()\n",
    "region = sess.boto_session.region_name\n",
    "account = sess.boto_session.client(\"sts\").get_caller_identity()[\"Account\"]\n",
    "smclient = boto3.Session().client('sagemaker')\n",
    "bucket = sess.default_bucket()\n",
    "stack_name= \"active-learning-stack\"\n",
    "key = \"sagemaker-byoal\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use this notebook to tokenize our dataset and create a training dataset, add a containerized model to ECR, and train the model. The notebook will produce an image name in ECR which can be used for training and inference across Amazon SageMaker. \n",
    "\n",
    "We use a Keras deep learning model for demonstration purposes only. The methodology for developing and containerizing our model was inspired by the tutorial [Take an ML from idea to production using Amazon SageMaker](https://github.com/aws-samples/amazon-sagemaker-keras-text-classification) and is not included in the notebook. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing and Tokenizing the data\n",
    "\n",
    "First we will download the dataset, read the csv news dataset using pandas and clean the data:\n",
    "\n",
    "* We make all alphanumeric characters lowercase and replace undesired characters. \n",
    "* We remove stop words and empty records. \n",
    "\n",
    "The result is saved into a CSV formatted file.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! wget -nc https://archive.ics.uci.edu/ml/machine-learning-databases/00359/NewsAggregatorDataset.zip --no-check-certificate && unzip -o NewsAggregatorDataset.zip"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the column names required from the downloaded dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = [\"TITLE\", \"URL\", \"PUBLISHER\", \"CATEGORY\", \"STORY\", \"HOSTNAME\", \"TIMESTAMP\"]\n",
    "manifest_file = \"partially-labeled.manifest\"\n",
    "news_data_all = pd.read_csv(\"newsCorpora.csv\", names=column_names, header=None, delimiter=\"\\t\")\n",
    "news_data = news_data_all.sample(n=10000, random_state=42)\n",
    "news_data = news_data[[\"TITLE\", \"CATEGORY\"]]\n",
    "news_data "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below cell will clean our data set using pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_data[\"TITLE\"].replace('\"', \"\", inplace=True, regex=True)\n",
    "news_data[\"TITLE\"].replace(\"[^\\w\\s]\", \"\", inplace=True, regex=True)\n",
    "news_data[\"TITLE\"] = news_data[\"TITLE\"].str.split(\"\\n\").str[0]\n",
    "news_data[\"CATEGORY\"] = news_data[\"CATEGORY\"].astype(\"category\").cat.codes\n",
    "news_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed = news_data[\"TITLE\"].str.lower().replace('\"', \"\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below cell creates the `news_subset.csv` which is used to manifest file for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_data.to_csv(\"news_subset.csv\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we use the [Keras Tokenizer class](https://keras.io/preprocessing/text/) to tokenize our dataset and upload it to S3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os, pickle\n",
    "\n",
    "from sklearn.feature_extraction import _stop_words\n",
    "\n",
    "stop_words = _stop_words.ENGLISH_STOP_WORDS\n",
    "import os, sys, sagemaker, tensorflow as tf, pandas as pd, boto3, numpy as np\n",
    "\n",
    "train_s3_key = \"sagemaker/news_subset.csv\"\n",
    "boto3.resource(\"s3\").Bucket(bucket).upload_file(\"news_subset.csv\", train_s3_key)\n",
    "\n",
    "column_names = [\"TITLE\", \"CATEGORY\"]\n",
    "tf_train = pd.read_csv(\n",
    "    \"news_subset.csv\", names=column_names, header=None, skiprows=[0], delimiter=\",\"\n",
    ")\n",
    "tf_train = tf_train[column_names]\n",
    "\n",
    "tf_train[\"TITLE\"] = tf_train[\"TITLE\"].str.lower().replace(\"[^\\w\\s]\", \"\")\n",
    "tf_train[\"TITLE\"] = tf_train[\"TITLE\"].apply(\n",
    "    lambda x: \" \".join([word for word in x.split() if word not in (stop_words)])\n",
    ")\n",
    "tf_train.dropna(inplace=True)\n",
    "\n",
    "cat = tf_train[\"CATEGORY\"].astype(\"category\").cat.categories\n",
    "tf_train[\"CATEGORY\"] = tf_train[\"CATEGORY\"].astype(\"category\").cat.codes\n",
    "y = tf_train[\"CATEGORY\"].values\n",
    "\n",
    "\n",
    "max_features = 5000  # we set maximum number of words to 5000\n",
    "maxlen = 100  # and maximum sequence length to 100\n",
    "embedding_dim = 50  # this is the final dimension of the embedding space.\n",
    "tok = tf.keras.preprocessing.text.Tokenizer(num_words=max_features)  # tokenizer step\n",
    "tok.fit_on_texts(list(tf_train[\"TITLE\"]))  # fit to cleaned text\n",
    "with open(\"tokenizer.pickle\", \"wb\") as handle:\n",
    "    pickle.dump(tok, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "boto3.resource(\"s3\").Bucket(bucket).upload_file(\"tokenizer.pickle\", key + \"/tokenizer.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below cell will update the value of *tokenizer_bucket* in our training and prediction scripts within the container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def inplace_string_replace(filename, old_string, new_string):\n",
    "    with open(filename) as f:\n",
    "        updated_text = f.read().replace(old_string, new_string)\n",
    "\n",
    "    with open(filename, \"w\") as f:\n",
    "        f.write(updated_text)\n",
    "\n",
    "\n",
    "old_code = \"tokenizer_bucket = '<Update tokenizer bucket here>'\"\n",
    "new_code = \"tokenizer_bucket = '{}'\".format(bucket)\n",
    "inplace_string_replace(\"./container/news-classifier/train\", old_code, new_code)\n",
    "inplace_string_replace(\"./container/news-classifier/predictor.py\", old_code, new_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We extract the first 1000 entries for training and add them to a manifest file. Then, we save our training manifest file in S3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "column_names = [\"TITLE\", \"CATEGORY\"]\n",
    "\n",
    "tf_train = pd.read_csv(\n",
    "    \"news_subset.csv\", names=column_names, header=None, skiprows=[0], delimiter=\",\"\n",
    ")\n",
    "tf_train = tf_train[[\"TITLE\", \"CATEGORY\"]]\n",
    "tf_train[\"TITLE\"] = tf_train[\"TITLE\"].str.replace('\"', \"\").replace(\"\\r\", \"\")\n",
    "tf_train[\"CATEGORY\"] = tf_train[\"CATEGORY\"].astype(\"category\").cat.codes\n",
    "\n",
    "val_file = \"validation-manifest\"\n",
    "series = pd.Series(\n",
    "    data=tf_train.iloc[:1000].TITLE.values, index=tf_train.iloc[:1000].CATEGORY.values\n",
    ")\n",
    "with open(val_file, \"w\") as outfile:\n",
    "    for items in series.items():\n",
    "        outfile.write('{\"category\":' + str(items[0]) + ',\"source\":\"' + items[1] + '\"}\\n')\n",
    "boto3.resource(\"s3\").Bucket(bucket).upload_file(val_file, key + \"/\" + val_file)\n",
    "valdiate_s3_uri = \"s3://{}/{}\".format(bucket, key + \"/\" + val_file)\n",
    "\n",
    "train_file = \"train-manifest\"\n",
    "series = pd.Series(\n",
    "    data=tf_train.iloc[1000:7000].TITLE.values, index=tf_train.iloc[1000:7000].CATEGORY.values\n",
    ")\n",
    "with open(train_file, \"w\") as outfile:\n",
    "    for items in series.items():\n",
    "        outfile.write('{\"category\":' + str(items[0]) + ',\"source\":\"' + items[1] + '\"}\\n')\n",
    "\n",
    "boto3.resource(\"s3\").Bucket(bucket).upload_file(train_file, key + \"/\" + train_file)\n",
    "train_s3_uri = \"s3://{}/{}\".format(bucket, key + \"/\" + train_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding the Containerized ML Model to ECR\n",
    "\n",
    "Setup ECR repoisitory name and image version "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "repo_name=\"news-classifier\"\n",
    "image_version=\"1.0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell will build a Amazon SageMaker-compatible Docker images directly from your Amazon SageMaker Studio environment.The CLI abstracts the previous need to set up a secondary build environment and allows you to focus and spend time on the ML problem you’re trying to solve as opposed to creating workflows for Docker builds. The new CLI automatically sets up your reusable build environment that you interact with via high-level commands. You essentially tell the CLI to build your image, without having to worry about the underlying workflow orchestrated through the CLI, and the output is a link to your Amazon Elastic Container Registry (Amazon ECR) image location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build docker container and push it to ECR\n",
    "\n",
    "Image URI is printed at the end of successful completion of SM Docker build command . This command takes approximately 4 mins to get completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    " %%bash -s  \"$repo_name\"  \"$image_version\"\n",
    "    \n",
    "cd container\n",
    "\n",
    "sm-docker build  .  --repository  ${1}:${2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Training our Model\n",
    "\n",
    "We train our model on the training data that we extracted above and see the accuracy returned by our algorithm in Amazon SageMaker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.estimator import Estimator\n",
    "\n",
    "image_uri=\"{0}.dkr.ecr.{1}.amazonaws.com/{2}:{3}\".format(account, region, repo_name, image_version)\n",
    "print(image_uri)\n",
    "\n",
    "estimator = Estimator(\n",
    "    image_uri=image_uri, role=role, instance_count=1, instance_type=\"ml.m5.xlarge\"\n",
    ")\n",
    "\n",
    "estimator.fit({\"training\": train_s3_uri, \"validation\": valdiate_s3_uri})\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Part 2: Use  model for Active Labeling workflow \n",
    "\n",
    "Update template.yaml . The template.yaml is leverage by AWS SAM to build out the backend infrastructure consisting of AWS step functions, helper utiltiies and AWS lambda functions\n",
    "\n",
    "Update configurations variables for Active Learning process  :\n",
    "\n",
    "- `byom` : (Bring your own model)  . This parameter determines whether the Lambda function used for configuring the training parameters returns the Amazon Blazing Text algorithm or your own custom model docker image  . This is set to to `true` because we are using our own custom ML model \n",
    "- `byomimage` : Your own custom model image\n",
    "- `sagemaker_program` :  This parameter determines the training script to be used for training your model . In this case we are using our own custom built docker image that contains the training script . Hence, setting this paameter to NotApplicable\n",
    "- `sagemaker_submit_directory` : The directory which contains the training source code or other dependencies aside from the entry point file . In this case we are using our own custom built docker image that contains the training script and other dependencies . Hence, setting this parameter to NotApplicable\n",
    "- `pretrain_model` : This parameter determines if the active learning process is using pretrained model or not   . This is set to to `false` because we are using our own custom ML model .\n",
    "- `pretrain_algo_train_repo` :  This parameter refers to the training image URI of our  pretrained BERT algorithm . Because we are not using a pretrained BERT model, setting this parameter to NotApplicable\n",
    "- `base_model_uri` : The URI of the pretrained BERT model which will be fine tuned with propriatary data. Because we are not using pretrained models, setting this parameter to NotApplicable\n",
    "- `pretrain_algo_inference_repo` :  This parameter refers to th inference image URI of our  pretrained BERT algorithm . Because we are not using a pretrained BERT model, setting this parameter to NotApplicable\n",
    "\n",
    "\n",
    "Update Batch Strategy to `Single` in the `CreateTransformJob` step of the ActiveLearning-active-learning-stack state machine.\n",
    "This is because the TensorFlow algorithm used here supports  `SingleRecord` \n",
    "- `BatchStrategy `: `SingleRecord`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash -s  \"$image_uri\"\n",
    "cd src\n",
    "\n",
    "# Update byom value to true \n",
    "sed  -i  \"0,/^\\([[:space:]]*byom: *\\).*/s//\\1\"true\"/\"  template.yaml\n",
    "\n",
    "#Update byomimage value to your own custom ML image\n",
    "sed  -i  \"0,/^\\([[:space:]]*byomimage: *\\).*/s//\\1${1//\\//\\\\\\/}/\"  template.yaml\n",
    "\n",
    "#Update Training script for PreTrained model to  Not Applicable\n",
    "sed  -i  \"0,/^\\([[:space:]]*sagemaker_program: *\\).*/s//\\1\"NotApplicable\"/\"   template.yaml\n",
    "\n",
    "#Update Pretrained Model flag to False\n",
    "sed  -i  \"0,/^\\([[:space:]]*pretrain_model: *\\).*/s//\\1\"false\"/\"   template.yaml\n",
    "\n",
    "#Update Pretrained algorithm training repository to NotApplicable\n",
    "sed  -i  \"0,/^\\([[:space:]]*pretrain_algo_train_repo: *\\).*/s//\\1\"NotApplicable\"/\"  template.yaml\n",
    "\n",
    "#Update SageMaker Submit Directory to NotApplicable\n",
    "sed  -i  \"0,/^\\([[:space:]]*sagemaker_submit_directory: *\\).*/s//\\1\"NotApplicable\"/\"   template.yaml\n",
    "\n",
    "#Update base pretrained model URI to NotApplicable\n",
    "sed  -i  \"0,/^\\([[:space:]]*base_model_uri: *\\).*/s//\\1\"NotApplicable\"/\"   template.yaml\n",
    "\n",
    "#Updated Pretrained  algorithm inference  reposiistory  to NotApplicable\n",
    "sed  -i  \"0,/^\\([[:space:]]*pretrain_algo_inference_repo: *\\).*/s//\\1\"NotApplicable\"/\"   template.yaml\n",
    "\n",
    "#Update BatchStrategy to SingleRecord\n",
    "sed -i 's/MultiRecord/SingleRecord/g'  template.yaml\n",
    "\n",
    "cat template.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Use `sam build` to update the AWS CloudFormation template and `sam deploy` to deploy the AWS CLouformation change set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash -s  \"$region\"  \"$stack_name\"  \"$bucket\"\n",
    "\n",
    "# Change directory to src folder\n",
    "cd src\n",
    "\n",
    "#Delete SAM build folder to clean up any exisiting SAM templates\n",
    "rm  -rf  .aws-sam\n",
    "\n",
    "#Build SAM artifacts to deploy AWS Cloudformation template\n",
    "sam build\n",
    "\n",
    "#Deploy SAM template\n",
    "sam deploy  --region ${1}  --stack-name ${2}  --s3-bucket ${3}  --capabilities CAPABILITY_IAM CAPABILITY_AUTO_EXPAND\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "#### Prepare labeling input manifest file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "We will create an input manifest file for our active learning workflow using the newsCorpora.csv file from the [UCI News Dataset](https://archive.ics.uci.edu/ml/datasets/News+Aggregator). This dataset contains a list of about 420,000 articles that fall into one of four categories: Business (b), Science & Technology (t), Entertainment (e) and Health & Medicine (m). We will randomly choose 10,000 articles from that file to create our dataset.\n",
    "\n",
    "For the active learning loop to start, 20% of the data must be labeled. To quickly test the active learning component, we will include 20% (`labeled_count`) of the original labels provided in the dataset in our input manifest. We use this partially-labeled dataset as the input to the active learning loop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "The following cell will create our partially-labeled input manifest file, and push it to our S3 bucket. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "total = len(news_data)\n",
    "labeled_count = int(total / 5)  # 20% of the dataset is labeled.\n",
    "label_map = {\n",
    "    \"b\": \"Business\",\n",
    "    \"e\": \"Entertainment\",\n",
    "    \"m\": \"Health & Medicine\",\n",
    "    \"t\": \"Science and Technology\",\n",
    "}\n",
    "labeled_series = pd.Series(\n",
    "    data=news_data.iloc[:labeled_count].TITLE.values,\n",
    "    index=news_data.iloc[:labeled_count].CATEGORY.values,\n",
    ")\n",
    "annotation_metadata = b\"\"\"{ \"category-metadata\" : { \"confidence\": 1.0, \"human-annotated\": \"yes\", \"type\": \"groundtruth/text-classification\"} }\"\"\"\n",
    "annotation_metadata_dict = json.loads(annotation_metadata)\n",
    "with open(manifest_file, \"w\") as outfile:\n",
    "    for items in labeled_series.items():\n",
    "        labeled_record = dict()\n",
    "        labeled_record[\"source\"] = items[1]\n",
    "        labeled_record[\"category\"] = int(items[0])\n",
    "        labeled_record.update(annotation_metadata_dict)\n",
    "        outfile.write(json.dumps(labeled_record) + \"\\n\")\n",
    "\n",
    "unlabeled_series = pd.Series(\n",
    "    data=news_data.iloc[labeled_count:].TITLE.values,\n",
    "    index=news_data.iloc[labeled_count:].CATEGORY.values,\n",
    ")\n",
    "with open(manifest_file, \"a\") as outfile:\n",
    "    for items in unlabeled_series.items():\n",
    "        outfile.write('{\"source\":\"' + items[1] + '\"}\\n')\n",
    "\n",
    "boto3.resource(\"s3\").Bucket(bucket).upload_file(manifest_file, key + \"/\" + manifest_file)\n",
    "manifest_file_uri = \"s3://{}/{}\".format(bucket, key + \"/\" + manifest_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# Use s3 client to upload relevant json strings to s3.\n",
    "s3_client = boto3.client(\"s3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "This cell will specify the labels that workers will use to categorize the articles. To customize your labeling job, add your own labels here. To learn more, see [LabelCategoryConfigS3Uri](https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_CreateLabelingJob.html#sagemaker-CreateLabelingJob-request-LabelCategoryConfigS3Uri)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "label_file_name = \"class_labels.json\"\n",
    "label_file = \"\"\"{\n",
    "    \"document-version\": \"2018-11-28\",\n",
    "    \"labels\": [\n",
    "        {\n",
    "            \"label\": \"Business\"\n",
    "        },\n",
    "        {\n",
    "            \"label\": \"Entertainment\"\n",
    "        },\n",
    "        {\n",
    "            \"label\": \"Health & Medicine\"\n",
    "        },\n",
    "        {\n",
    "            \"label\": \"Science and Technology\"\n",
    "        }\n",
    "    ]\n",
    "}\"\"\"\n",
    "\n",
    "s3_client.put_object(Body=label_file, Bucket=bucket, Key=key + \"/\" + label_file_name)\n",
    "label_file_uri = \"s3://{}/{}\".format(bucket, key + \"/\" + label_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "The following cell will specify our custom worker task template. This template will configure the UI that workers will see when they open our text classification labeling job tasks. To learn how to customize this cell, see  [Creating your custom labeling task template](https://docs.aws.amazon.com/sagemaker/latest/dg/sms-custom-templates-step2.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "template_file_name = \"instructions.template\"\n",
    "template_file = r\"\"\"\n",
    "<script src=\"https://assets.crowd.aws/crowd-html-elements.js\"></script>\n",
    "<crowd-form>\n",
    "  <crowd-classifier\n",
    "    name=\"crowd-classifier\"\n",
    "    categories=\"{{ task.input.labels | to_json | escape }}\"\n",
    "    header=\"Select the news title corresponding to the 4 categories. (b) for Business, (e) for Entertainment, (m) for Health and Medicine and (t) for Science and Technology.\"\n",
    "  >\n",
    "    <classification-target> {{ task.input.taskObject }} </classification-target>\n",
    "    <full-instructions header=\"Classifier instructions\">\n",
    "      <ol><li><strong>Read</strong> the text carefully.</li><li><strong>Read</strong> the examples to understand more about the options.</li><li><strong>Choose</strong> the appropriate label that best suits the text.</li></ol>\n",
    "    </full-instructions>\n",
    "    <short-instructions>\n",
    "      <p>Example Business title:</p><p>US open: Stocks fall after Fed official hints at accelerated tapering.</p><p><br>\n",
    "      </p><p>Example Entertainment title:</p><p>CBS negotiates three more seasons for The Big Bang Theory</p><p><br>\n",
    "      </p><p>Example Health & Medicine title:</p><p>Blood Test Could Predict Alzheimer's. Good News? </p><p><br>\n",
    "      </p><p>Example Science and Technology (t) title:</p><p>Elephants tell human friend from foe by voice.</p><p><br>\n",
    "      </p>\n",
    "    </short-instructions>\n",
    "  </crowd-classifier>\n",
    "</crowd-form>\n",
    "\"\"\"\n",
    "\n",
    "s3_client.put_object(Body=template_file, Bucket=bucket, Key=key + \"/\" + template_file_name)\n",
    "template_file_uri = \"s3://{}/{}\".format(bucket, key + \"/\" + template_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "To use a private work team to labeling your data objects, set `USE_PRIVATE_WORKFORCE` to `True` and input your work team ARN for `private_workteam_arn`. You must have a private workforce in the same AWS Region as your labeling job task request to use a private work team. To learn more see [Use a Private Workforce](https://docs.aws.amazon.com/sagemaker/latest/dg/sms-workforce-private.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "USE_PRIVATE_WORKFORCE = True\n",
    "private_workteam_arn = \"Enter your Private Worker ARN\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "The below cell will automatically configure a public workforce ARN and pre- and post-annotation ARNs (`prehuman_arn` and `acs_arn` respectively). If `USE_PRIVATE_WORKFORCE` is `False` a public workforce will be used to create your labeling job request. \n",
    "\n",
    "To customize your labeling job task type, you will need to modify `prehuman_arn` and `acs_arn`. \n",
    "\n",
    "If you are using one of the Ground Truth built-in task types, you can find pre- and post-annotation lambda ARNs using the following links. \n",
    "* Pre-annotation lambda ARNs for built in task types can be found in [HumanTaskConfig](https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_HumanTaskConfig.html#API_HumanTaskConfig_Contents).\n",
    "* Post-annotation lambda ARNs (Annotation Consolidation Lambda) for built in task types can be found in [AnnotationConsolidationConfig](https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_AnnotationConsolidationConfig.html#sagemaker-Type-AnnotationConsolidationConfig-AnnotationConsolidationLambdaArn).\n",
    "\n",
    "If you are creating a custom labeling job task, see [Step 3: Processing with AWS Lambda\n",
    "](https://docs.aws.amazon.com/sagemaker/latest/dg/sms-custom-templates-step3.html) learn how to create custom pre- and post-annotation lambda ARNs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# Specify ARNs for resources needed to run a text classification job.\n",
    "ac_arn_map = {\n",
    "    \"us-west-2\": \"081040173940\",\n",
    "    \"us-east-1\": \"432418664414\",\n",
    "    \"us-east-2\": \"266458841044\",\n",
    "    \"eu-west-1\": \"568282634449\",\n",
    "    \"ap-northeast-1\": \"477331159723\",\n",
    "}\n",
    "\n",
    "public_workteam_arn = \"arn:aws:sagemaker:{}:394669845002:workteam/public-crowd/default\".format(\n",
    "    region\n",
    ")\n",
    "prehuman_arn = \"arn:aws:lambda:{}:{}:function:PRE-TextMultiClass\".format(region, ac_arn_map[region])\n",
    "acs_arn = \"arn:aws:lambda:{}:{}:function:ACS-TextMultiClass\".format(region, ac_arn_map[region])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "The following cell specifies our labeling job name, the description workers see, and tags that workers can use to find our labeling job task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "job_name_prefix = \"byoal-news\"\n",
    "task_description = \"Classify news title to one of these 4 categories.\"\n",
    "task_keywords = [\"text\", \"classification\", \"humans\", \"news\"]\n",
    "task_title = task_description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Modify the following request to customize your labeling job request. For more information on the parameters below, see [CreateLabelingJob](https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_CreateLabelingJob.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "human_task_config = {\n",
    "    \"AnnotationConsolidationConfig\": {\n",
    "        \"AnnotationConsolidationLambdaArn\": acs_arn,\n",
    "    },\n",
    "    \"PreHumanTaskLambdaArn\": prehuman_arn,\n",
    "    \"MaxConcurrentTaskCount\": 10,  # 10 texts will be sent at a time to the workteam.\n",
    "    \"NumberOfHumanWorkersPerDataObject\": 1,  # 1 workers will be enough to label each text.\n",
    "    \"TaskAvailabilityLifetimeInSeconds\": 21600,  # Your work team has 6 hours to complete all pending tasks.\n",
    "    \"TaskDescription\": task_description,\n",
    "    \"TaskKeywords\": task_keywords,\n",
    "    \"TaskTimeLimitInSeconds\": 300,  # Each text must be labeled within 5 minutes.\n",
    "    \"TaskTitle\": task_title,\n",
    "    \"UiConfig\": {\n",
    "        \"UiTemplateS3Uri\": template_file_uri,\n",
    "    },\n",
    "}\n",
    "\n",
    "if not USE_PRIVATE_WORKFORCE:\n",
    "    human_task_config[\"PublicWorkforceTaskPrice\"] = {\n",
    "        \"AmountInUsd\": {\n",
    "            \"Dollars\": 0,\n",
    "            \"Cents\": 1,\n",
    "            \"TenthFractionsOfACent\": 2,\n",
    "        }\n",
    "    }\n",
    "    human_task_config[\"WorkteamArn\"] = public_workteam_arn\n",
    "else:\n",
    "    human_task_config[\"WorkteamArn\"] = private_workteam_arn\n",
    "\n",
    "ground_truth_request = {\n",
    "    \"InputConfig\": {\n",
    "        \"DataSource\": {\n",
    "            \"S3DataSource\": {\n",
    "                \"ManifestS3Uri\": manifest_file_uri,\n",
    "            }\n",
    "        },\n",
    "        \"DataAttributes\": {\n",
    "            \"ContentClassifiers\": [\"FreeOfPersonallyIdentifiableInformation\", \"FreeOfAdultContent\"]\n",
    "        },\n",
    "    },\n",
    "    \"OutputConfig\": {\n",
    "        \"S3OutputPath\": \"s3://{}/{}/output/\".format(bucket, key),\n",
    "    },\n",
    "    \"HumanTaskConfig\": human_task_config,\n",
    "    \"LabelingJobNamePrefix\": job_name_prefix,\n",
    "    \"RoleArn\": role,\n",
    "    \"LabelAttributeName\": \"category\",\n",
    "    \"LabelCategoryConfigS3Uri\": label_file_uri,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "print(json.dumps(ground_truth_request, indent=2))\n",
    "step_func_input=json.dumps(ground_truth_request,default=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get Stepfunction Client\n",
    "sfn=boto3.client('stepfunctions', region_name=region)\n",
    "stateMachineArn=\"arn:aws:states:{}:{}:stateMachine:ActiveLearningLoop-active-learning-stack\".format(region,account)\n",
    "response = sfn.start_execution(\n",
    "    stateMachineArn=stateMachineArn,\n",
    "    input=step_func_input\n",
    "    \n",
    ")\n",
    "executionArn=response[\"executionArn\"] \n",
    "\n",
    "print(json.dumps(response, indent=2, default=str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please refer to lab instructions for next steps on View active data labeling workflow and Human Annotation WorkFlow\n",
    "\n",
    "On successful completion of the active learning loop, the state machine will output the final output manifest file and the latest trained model output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up \n",
    "\n",
    "# Stop Active Learning state machine\n",
    "if (sfn.describe_execution(executionArn=executionArn)[\"status\"]==\"RUNNING\" ):\n",
    "    sfn.stop_execution(executionArn=executionArn)\n",
    "    print('State Machine Execution Stopped :  ' + executionArn)\n",
    "\n",
    "# Stop Ground Truth Labeling jobs that are InProgress or Initializing\n",
    "response = smclient .list_labeling_jobs(NameContains='byoal-news')\n",
    "for i in range(len(response['LabelingJobSummaryList'])):\n",
    "    if ( (response['LabelingJobSummaryList'][i]['LabelingJobStatus'] == 'InProgress' ) or  (response['LabelingJobSummaryList'][i]['LabelingJobStatus'] == 'Initializing')):\n",
    "        label_job_name=response['LabelingJobSummaryList'][i]['LabelingJobName']\n",
    "        smclient.stop_labeling_job(LabelingJobName=label_job_name)\n",
    "        print('Stopping Labeling Job:  ' + label_job_name )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete AWS ECR Repo -\n",
    "!aws ecr delete-repository --repository-name news-classifier --force"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s  \"$region\"  \"$stack_name\"\n",
    "\n",
    "#Delete CloudFormation Stack \n",
    "sam delete  --region ${1}  --stack-name ${2}  --no-prompts"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (TensorFlow 2.10.0 Python 3.9 CPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/tensorflow-2.10.1-cpu-py39-ubuntu20.04-sagemaker-v1.2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
